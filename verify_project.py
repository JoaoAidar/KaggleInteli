"""
Project verification script.
Checks that all required files exist and are properly structured.
"""
import os
import json
import sys

def check_file(path, description):
    """Check if a file exists."""
    if os.path.exists(path):
        print(f"âœ“ {description}: {path}")
        return True
    else:
        print(f"âœ— {description}: {path} (MISSING)")
        return False

def check_directory(path, description):
    """Check if a directory exists."""
    if os.path.isdir(path):
        print(f"âœ“ {description}: {path}/")
        return True
    else:
        print(f"âœ— {description}: {path}/ (MISSING)")
        return False

def main():
    """Run verification checks."""
    print("="*60)
    print("PROJECT VERIFICATION")
    print("="*60)
    
    all_checks = []
    
    # Check directories
    print("\nðŸ“ Checking Directories...")
    all_checks.append(check_directory("data", "Data directory"))
    all_checks.append(check_directory("src", "Source code directory"))
    all_checks.append(check_directory("notebooks", "Notebooks directory"))
    all_checks.append(check_directory("reports", "Reports directory"))
    
    # Check data files (user-provided)
    print("\nðŸ“Š Checking Data Files...")
    all_checks.append(check_file("data/train.csv", "Training data"))
    all_checks.append(check_file("data/test.csv", "Test data"))
    all_checks.append(check_file("data/sample_submission.csv", "Sample submission"))
    
    # Check source files
    print("\nðŸ Checking Source Files...")
    all_checks.append(check_file("src/__init__.py", "Package init"))
    all_checks.append(check_file("src/io_utils.py", "I/O utilities"))
    all_checks.append(check_file("src/features.py", "Feature engineering"))
    all_checks.append(check_file("src/modeling.py", "Model building"))
    all_checks.append(check_file("src/evaluation.py", "Evaluation utilities"))
    all_checks.append(check_file("src/cli.py", "CLI interface"))
    
    # Check notebook
    print("\nðŸ““ Checking Notebook...")
    notebook_exists = check_file("notebooks/01_startup_success.ipynb", "Main notebook")
    all_checks.append(notebook_exists)
    
    if notebook_exists:
        try:
            with open("notebooks/01_startup_success.ipynb", 'r') as f:
                notebook = json.load(f)
                num_cells = len(notebook.get('cells', []))
                print(f"  â†’ Notebook has {num_cells} cells")
                if num_cells >= 50:
                    print(f"  âœ“ Sufficient cells (expected ~55)")
                else:
                    print(f"  âš  Warning: Expected ~55 cells, found {num_cells}")
        except Exception as e:
            print(f"  âœ— Error reading notebook: {e}")
            all_checks.append(False)
    
    # Check documentation
    print("\nðŸ“„ Checking Documentation...")
    all_checks.append(check_file("README.md", "README"))
    all_checks.append(check_file("Makefile", "Makefile"))
    all_checks.append(check_file("PROJECT_SUMMARY.md", "Project summary"))
    
    # Check generated files (optional)
    print("\nðŸ“ˆ Checking Generated Files (optional)...")
    if os.path.exists("reports/cv_metrics.csv"):
        print("âœ“ CV metrics file exists: reports/cv_metrics.csv")
    else:
        print("â„¹ CV metrics not yet generated (run 'make cv')")
    
    if os.path.exists("submission.csv"):
        print("âœ“ Submission file exists: submission.csv")
        # Check format
        with open("submission.csv", 'r') as f:
            first_line = f.readline().strip()
            if first_line == "id,labels":
                print("  âœ“ Correct header format")
            else:
                print(f"  âœ— Incorrect header: {first_line}")
    else:
        print("â„¹ Submission not yet generated (run 'make submit')")
    
    # Test imports
    print("\nðŸ”§ Testing Module Imports...")
    try:
        from src.io_utils import load_data, get_target_name, save_submission
        print("âœ“ io_utils imports successfully")
        all_checks.append(True)
    except Exception as e:
        print(f"âœ— io_utils import failed: {e}")
        all_checks.append(False)
    
    try:
        from src.features import split_columns, build_preprocessor
        print("âœ“ features imports successfully")
        all_checks.append(True)
    except Exception as e:
        print(f"âœ— features import failed: {e}")
        all_checks.append(False)
    
    try:
        from src.modeling import build_pipelines, random_search_rf
        print("âœ“ modeling imports successfully")
        all_checks.append(True)
    except Exception as e:
        print(f"âœ— modeling import failed: {e}")
        all_checks.append(False)
    
    try:
        from src.evaluation import evaluate_all, cv_report, assert_min_accuracy
        print("âœ“ evaluation imports successfully")
        all_checks.append(True)
    except Exception as e:
        print(f"âœ— evaluation import failed: {e}")
        all_checks.append(False)
    
    # Summary
    print("\n" + "="*60)
    print("VERIFICATION SUMMARY")
    print("="*60)
    
    passed = sum(all_checks)
    total = len(all_checks)
    percentage = (passed / total) * 100 if total > 0 else 0
    
    print(f"\nChecks passed: {passed}/{total} ({percentage:.1f}%)")
    
    if all(all_checks):
        print("\nâœ… ALL CHECKS PASSED!")
        print("\nProject is ready for use. Next steps:")
        print("  1. Run 'make eda' for exploratory data analysis")
        print("  2. Run 'make cv' for cross-validation")
        print("  3. Run 'make tune' for hyperparameter tuning")
        print("  4. Run 'make submit' to generate submission")
        print("\nOr run 'make all' to execute the complete pipeline.")
        return 0
    else:
        print("\nâš  SOME CHECKS FAILED")
        print("\nPlease review the errors above and fix any issues.")
        return 1

if __name__ == "__main__":
    sys.exit(main())

