# Previs√£o de Sucesso de Startups - Competi√ß√£o Kaggle

**Competi√ß√£o:** [Inteli-M3] Campeonato 2025

---

## üèÜ Melhor Modelo: 81.88% de Acur√°cia no Kaggle

### Vis√£o Geral

Este projeto alcan√ßou **81.88% de acur√°cia** na competi√ß√£o Kaggle utilizando uma abordagem de **Ensemble de Vota√ß√£o Majorit√°ria (Hard Voting)** com dois modelos Random Forest complementares. Esta abordagem simples e robusta superou m√©todos mais complexos como stacking e soft voting, demonstrando que simplicidade e diversidade de modelos s√£o mais eficazes que complexidade excessiva.

**Arquivo de Submiss√£o:** `submission_majority_vote.csv`

---

## üéØ Arquitetura do Modelo

### Ensemble de Vota√ß√£o Majorit√°ria (Hard Voting)

O modelo vencedor utiliza **vota√ß√£o majorit√°ria** entre dois modelos Random Forest treinados com diferentes configura√ß√µes:

#### Modelos Base:

1. **RF_Original** - Random Forest com features originais
   - **Features:** 31 features originais do dataset
   - **Acur√°cia CV:** 79.88% ¬± 3.85%
   - **Hiperpar√¢metros:**
     - `n_estimators`: 500
     - `max_depth`: 10
     - `min_samples_split`: 5
     - `min_samples_leaf`: 1
     - `max_features`: 'log2'
     - `class_weight`: None

2. **RF_Poly** - Random Forest com features polinomiais
   - **Features:** 46 features (31 originais + 15 polinomiais de grau 2)
   - **Acur√°cia CV:** 79.42% ¬± 3.96%
   - **Hiperpar√¢metros:**
     - `n_estimators`: 200
     - `max_depth`: None (sem limite)
     - `min_samples_split`: 10
     - `min_samples_leaf`: 2
     - `max_features`: 0.3
     - `class_weight`: 'balanced'

### Como Funciona a Vota√ß√£o Majorit√°ria

```python
# Cada modelo faz uma predi√ß√£o bin√°ria (0 ou 1)
RF_Original prediz: [1, 0, 1, 0, ...]
RF_Poly prediz:     [1, 1, 1, 0, ...]

# Vota√ß√£o majorit√°ria: se ambos concordam, usa o voto
# Se discordam, pode usar desempate ou voto do modelo mais confi√°vel
Predi√ß√£o final:     [1, 0/1, 1, 0, ...]
```

**Vantagens da Vota√ß√£o Majorit√°ria:**
- ‚úÖ Decis√µes discretas (0 ou 1) evitam overfitting de probabilidades
- ‚úÖ Robustez: erros de um modelo s√£o compensados pelo outro
- ‚úÖ Simplicidade: sem meta-learner complexo
- ‚úÖ Diversidade: diferentes features e hiperpar√¢metros capturam padr√µes complementares

---

## üìä M√©tricas de Desempenho

### Resultados do Ensemble

| M√©trica | Valor | Observa√ß√£o |
|---------|-------|------------|
| **Acur√°cia CV** | ~79.5% | M√©dia dos modelos base |
| **Acur√°cia Kaggle** | **81.88%** | Resultado final na competi√ß√£o |
| **Gap CV-Kaggle** | **+2.38pp** | Gap positivo indica excelente generaliza√ß√£o |
| **Predi√ß√µes** | 277 | 194 sucessos (70.0%), 83 falhas (30.0%) |

### Compara√ß√£o com Outras Abordagens

| Abordagem | Acur√°cia Kaggle | Gap CV-Kaggle | Status |
|-----------|-----------------|---------------|--------|
| **Hard Voting (RF+RF)** | **81.88%** | **+2.38pp** | ‚úÖ **MELHOR** |
| Soft Voting | 79.71% | +0.21pp | Bom |
| Weighted Ensemble | 79.71% | +0.21pp | Bom |
| Advanced RF | 78.99% | -0.11pp | OK |
| GridSearchCV RF | 78.26% | -2.24pp | Overfitting |
| Stacking (5 modelos) | 76.09% | -3.02pp | Overfitting severo |

**Insight Cr√≠tico:** M√©todos mais complexos (GridSearchCV, Stacking) tiveram **pior desempenho** devido a overfitting. A simplicidade da vota√ß√£o majorit√°ria foi a chave do sucesso.

---

## üí° Por Que Esta Abordagem Funciona

### 1. Diversidade de Modelos

**RF_Original vs RF_Poly:**
- **Features diferentes:** 31 vs 46 features
- **Hiperpar√¢metros diferentes:** Profundidade, n√∫mero de √°rvores, regulariza√ß√£o
- **Padr√µes complementares:** Cada modelo captura aspectos diferentes dos dados

**Resultado:** Erros dos modelos s√£o **n√£o-correlacionados**, permitindo que um compense o outro.

### 2. Vota√ß√£o Majorit√°ria > Soft Voting

**Hard Voting (Vota√ß√£o Majorit√°ria):**
```python
# Cada modelo vota 0 ou 1
Predi√ß√£o = maioria([modelo1.predict(), modelo2.predict()])
```

**Soft Voting (M√©dia de Probabilidades):**
```python
# M√©dia das probabilidades
Predi√ß√£o = m√©dia([modelo1.predict_proba(), modelo2.predict_proba()]) > 0.5
```

**Por que Hard Voting √© melhor:**
- ‚úÖ Decis√µes discretas s√£o mais robustas
- ‚úÖ Evita overfitting de probabilidades calibradas
- ‚úÖ Gap positivo (+2.38pp) vs gap pequeno do soft voting (+0.21pp)

### 3. Robustez ao Overfitting

**Evid√™ncia:**
- **Gap positivo (+2.38pp):** Modelo generaliza MELHOR no teste que no treino
- **M√©todos complexos falharam:**
  - GridSearchCV: -2.24pp gap (overfitting)
  - Stacking: -3.02pp gap (overfitting severo)
- **Simplicidade vence:** Menos par√¢metros = menos overfitting

### 4. Teto de Performance

**11 submiss√µes testadas, NENHUMA superou 81.88%:**
- Otimiza√ß√£o Bayesiana (LightGBM): 79.71%
- GridSearchCV (216 combina√ß√µes): 78.26%
- Stacking (5 modelos): 76.09%
- Threshold optimization: 78.99%

**Conclus√£o:** 81.88% representa o **teto de performance** para este dataset com as abordagens testadas.

---

## üîÑ Como Reproduzir

### Passo 1: Preparar o Ambiente

```bash
# Instalar depend√™ncias
pip install numpy pandas scikit-learn matplotlib seaborn

# Verificar estrutura do projeto
ls data/
# Esperado: train.csv, test.csv, sample_submission.csv
```

### Passo 2: Executar o Script de Ensemble

```bash
# Gerar as submiss√µes de ensemble
python create_ensemble_submissions.py
```

**Sa√≠da esperada:**
- `submission_majority_vote.csv` - Hard voting (MELHOR - 81.88%)
- `submission_voting_ensemble.csv` - Soft voting (79.71%)
- `submission_weighted_ensemble.csv` - Weighted voting (79.71%)

### Passo 3: Submeter ao Kaggle

1. Fazer upload de `submission_majority_vote.csv` no Kaggle
2. Verificar formato: 277 linhas, colunas `id` e `labels`
3. Resultado esperado: **~81.88% de acur√°cia**

### Estrutura do Arquivo de Submiss√£o

```csv
id,labels
0,1
1,0
2,1
...
276,1
```

---

## üéì Aprendizados Principais

### 1. Simplicidade > Complexidade

**O que funcionou:**
- ‚úÖ Hard voting com 2 modelos Random Forest
- ‚úÖ Hiperpar√¢metros simples e robustos
- ‚úÖ Features originais (31) + features polinomiais (46)

**O que N√ÉO funcionou:**
- ‚ùå Stacking com 5 modelos e meta-learner
- ‚ùå GridSearchCV com 216 combina√ß√µes
- ‚ùå Otimiza√ß√£o Bayesiana com 150 trials
- ‚ùå Feature engineering extensiva (>50 features)

**Li√ß√£o:** Occam's Razor se aplica - a solu√ß√£o mais simples √© frequentemente a melhor.

### 2. Otimiza√ß√£o Excessiva Prejudica

**Evid√™ncia:**
- GridSearchCV (80.50% CV) ‚Üí 78.26% Kaggle (-2.24pp)
- Baseline (80.18% CV) ‚Üí 78.26% Kaggle (-1.92pp)
- **Resultado:** Mesma performance no Kaggle, mas GridSearchCV teve mais overfitting

**Li√ß√£o:** Mais otimiza√ß√£o ‚â† melhor performance. Overfitting ao CV √© um risco real.

### 3. Gap CV-Kaggle √© Indicador Cr√≠tico

**Gaps Positivos (Boa Generaliza√ß√£o):**
- Hard voting: +2.38pp ‚úÖ
- Soft voting: +0.21pp ‚úÖ

**Gaps Negativos (Overfitting):**
- GridSearchCV: -2.24pp ‚ùå
- Stacking: -3.02pp ‚ùå

**Li√ß√£o:** Gap positivo √© raro e valioso - indica que o modelo generaliza melhor que o esperado.

### 4. Diversidade de Modelos √© Essencial

**Por que 2 Random Forests funcionaram:**
- Features diferentes (31 vs 46)
- Hiperpar√¢metros diferentes (profundidade, regulariza√ß√£o)
- Erros n√£o-correlacionados

**Li√ß√£o:** Diversidade > Quantidade. 2 modelos diversos > 5 modelos similares.

### 5. Dataset Pequeno Tem Limites

**Caracter√≠sticas:**
- 646 amostras de treino (pequeno)
- 31 features originais
- Ru√≠do inerente em predi√ß√£o de sucesso de startups

**Implica√ß√µes:**
- Teto de performance ~82%
- Modelos complexos overfitam facilmente
- Simplicidade √© crucial

---

## üìÅ Arquivos Relacionados

### Scripts Principais

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `create_ensemble_submissions.py` | Gera as 3 submiss√µes de ensemble |
| `run_rf_gridsearch_fast.py` | GridSearchCV RF (n√£o recomendado) |
| `run_stacking_ensemble.py` | Stacking ensemble (n√£o recomendado) |

### Submiss√µes Geradas

| Arquivo | Acur√°cia Kaggle | Recomenda√ß√£o |
|---------|-----------------|--------------|
| `submission_majority_vote.csv` | **81.88%** | ‚úÖ **USAR ESTE** |
| `submission_voting_ensemble.csv` | 79.71% | Alternativa |
| `submission_weighted_ensemble.csv` | 79.71% | Alternativa |

### Documenta√ß√£o

| Arquivo | Conte√∫do |
|---------|----------|
| `FINAL_RESULTS_ANALYSIS.md` | An√°lise completa dos resultados |
| `JOURNEY_SUMMARY.md` | Jornada de 78.26% ‚Üí 81.88% |
| `SUBMISSION_COMPARISON.md` | Compara√ß√£o detalhada de todas as submiss√µes |

---

## üìã Vis√£o Geral do Projeto


Prever o sucesso de startups (classifica√ß√£o bin√°ria) com base em features incluindo:
- Informa√ß√µes de financiamento (valores, rodadas, investidores)
- Localiza√ß√£o geogr√°fica (indicadores de estado)
- Categoria da ind√∫stria
- Conquistas de marcos (milestones)
- Redes de relacionamento

### Descri√ß√£o do Dataset

- **Conjunto de Treino**: 646 startups com resultados conhecidos
- **Conjunto de Teste**: 277 startups requerendo predi√ß√µes
- **Features**: 31 colunas originais (num√©ricas e categ√≥ricas)
- **Target**: Label bin√°rio (0 = falha, 1 = sucesso)
- **Distribui√ß√£o de Classes**: 64.7% sucesso, 35.3% falha

### M√©trica Alvo

- **Prim√°ria**: Acur√°cia ‚â• 80% (‚úÖ **Alcan√ßado: 81.88%**)
- **Secund√°ria**: Precis√£o, Recall, F1-score

---

## üõ† Stack T√©cnico

### Bibliotecas Utilizadas

**Core ML/Dados:**
- `numpy` - Computa√ß√µes num√©ricas
- `pandas` - Manipula√ß√£o de dados
- `scikit-learn` - Algoritmos de machine learning

**Visualiza√ß√£o:**
- `matplotlib` - Visualiza√ß√£o prim√°ria (obrigat√≥rio)
- `seaborn` - Melhorias opcionais de estilo

**Outros:**
- `jupyter` - Ambiente de notebook interativo
- `optuna` - Otimiza√ß√£o Bayesiana (usado em experimentos)
- `lightgbm`, `catboost` - Modelos alternativos testados

### Restri√ß√µes

‚úì Sem fontes de dados externas (apenas diret√≥rio `data/`)
‚úì Todo pr√©-processamento em pipelines (sem vazamento de dados)
‚úì Seeds aleat√≥rias fixas (`random_state=42`)
‚úì Compat√≠vel com Python 3.8+

---

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ data/                                    # Datasets fornecidos
‚îÇ   ‚îú‚îÄ‚îÄ train.csv                            # Dados de treino com labels
‚îÇ   ‚îú‚îÄ‚îÄ test.csv                             # Dados de teste para predi√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ sample_submission.csv                # Template de formato de submiss√£o
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01_startup_success.ipynb             # Notebook principal de an√°lise
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                          # Inicializa√ß√£o do pacote
‚îÇ   ‚îú‚îÄ‚îÄ io_utils.py                          # Utilit√°rios de carregamento/salvamento
‚îÇ   ‚îú‚îÄ‚îÄ features.py                          # Feature engineering & pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ model_zoo.py                         # Zoo de modelos (14 modelos testados)
‚îÇ   ‚îú‚îÄ‚îÄ modeling.py                          # Constru√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py                        # M√©tricas & valida√ß√£o cruzada
‚îÇ   ‚îî‚îÄ‚îÄ cli.py                               # Interface de linha de comando
‚îú‚îÄ‚îÄ reports/                                 # Relat√≥rios gerados
‚îÇ   ‚îú‚îÄ‚îÄ cv_metrics.csv                       # Resultados de valida√ß√£o cruzada
‚îÇ   ‚îú‚îÄ‚îÄ best_rf_params.json                  # Hiperpar√¢metros √≥timos do RF
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm_optimization_results.json   # Resultados LightGBM
‚îÇ   ‚îî‚îÄ‚îÄ weighted_ensemble_kaggle_results.json # Resultados ensemble ponderado
‚îú‚îÄ‚îÄ create_ensemble_submissions.py           # Script para gerar ensembles
‚îú‚îÄ‚îÄ run_rf_gridsearch_fast.py               # GridSearchCV RF
‚îú‚îÄ‚îÄ run_stacking_ensemble.py                # Stacking ensemble
‚îú‚îÄ‚îÄ run_lightgbm_optimization.py            # Otimiza√ß√£o LightGBM
‚îú‚îÄ‚îÄ run_catboost_optimization.py            # Otimiza√ß√£o CatBoost
‚îú‚îÄ‚îÄ submission_majority_vote.csv            # ‚úÖ MELHOR SUBMISS√ÉO (81.88%)
‚îú‚îÄ‚îÄ Makefile                                # Comandos de automa√ß√£o
‚îî‚îÄ‚îÄ README.md                               # Este arquivo
```

---

## üöÄ Instru√ß√µes de Configura√ß√£o

### Ambiente Local

```bash
# Instalar depend√™ncias principais
pip install numpy pandas scikit-learn matplotlib seaborn jupyter

# Instalar bibliotecas adicionais (para experimentos)
pip install optuna lightgbm catboost

# Verificar se os arquivos de dados existem
ls data/
# Esperado: train.csv, test.csv, sample_submission.csv

# Verificar estrutura do projeto
python -c "from src.io_utils import load_data; print('‚úì Setup completo!')"
```

### Ambiente Kaggle

1. Fazer upload de `notebooks/01_startup_success.ipynb` para o Kaggle
2. Anexar o dataset da competi√ß√£o
3. Executar todas as c√©lulas sequencialmente
4. Baixar `submission.csv`

### Reproduzir Melhor Resultado (81.88%)

```bash
# Op√ß√£o 1: Usar submiss√£o pr√©-gerada (mais r√°pido)
# Fazer upload de submission_majority_vote.csv diretamente no Kaggle

# Op√ß√£o 2: Gerar novamente (para verifica√ß√£o)
python create_ensemble_submissions.py
# Isso gerar√° submission_majority_vote.csv
```

---

## üíª Como Usar

### Op√ß√£o 1: Gerar Melhor Submiss√£o (Recomendado)

```bash
# Gerar as submiss√µes de ensemble (inclui a melhor: 81.88%)
python create_ensemble_submissions.py

# Arquivos gerados:
# - submission_majority_vote.csv (81.88% - USAR ESTE)
# - submission_voting_ensemble.csv (79.71%)
# - submission_weighted_ensemble.csv (79.71%)
```

### Op√ß√£o 2: Interface de Linha de Comando

#### Usando Makefile (Mais Simples)

```bash
# Executar an√°lise explorat√≥ria de dados
make eda

# Avalia√ß√£o de valida√ß√£o cruzada (todos os modelos)
make cv

# Ajuste de hiperpar√¢metros (Random Forest)
make tune

# Gerar submiss√£o com RF padr√£o
make train

# Gerar submiss√£o com RF ajustado
make train-best

# Submiss√£o r√°pida (executa train-best)
make submit

# Executar pipeline completo: eda ‚Üí cv ‚Üí tune ‚Üí submit
make all

# Limpar arquivos gerados
make clean
```

#### Usando Python CLI Diretamente

```bash
# An√°lise Explorat√≥ria de Dados
python -m src.cli eda --data-dir data

# Avalia√ß√£o de valida√ß√£o cruzada
python -m src.cli cv --data-dir data --output reports/cv_metrics.csv

# Ajuste de hiperpar√¢metros
python -m src.cli tune --data-dir data --seed 42 --output reports/best_rf_params.json

# Treinar e prever (RF padr√£o)
python -m src.cli train-predict --data-dir data --model rf --output submission.csv

# Treinar e prever (RF ajustado)
python -m src.cli train-predict --data-dir data --use-best-rf --output submission.csv

# Treinar e prever (Gradient Boosting)
python -m src.cli train-predict --data-dir data --model gb --output submission.csv
```

### Op√ß√£o 3: Jupyter Notebook (Interativo)

```bash
# Iniciar Jupyter
jupyter notebook

# Abrir notebooks/01_startup_success.ipynb
# Executar todas as c√©lulas sequencialmente (Cell ‚Üí Run All)
# Arquivo de submiss√£o ser√° gerado na raiz do projeto
```

---

## üìä Fluxo do Pipeline

### 1. An√°lise Explorat√≥ria de Dados (EDA)
- Formas e informa√ß√µes do dataset
- An√°lise de valores ausentes
- Identifica√ß√£o de tipos de features
- Distribui√ß√£o do target
- An√°lise de correla√ß√£o

### 2. Engenharia de Features
- **Features num√©ricas**: Imputa√ß√£o pela mediana + StandardScaler
- **Features categ√≥ricas**: Imputa√ß√£o pela moda + OneHotEncoder (min_frequency=10)
- **Features polinomiais**: Grau 2 para intera√ß√µes (usado em RF_Poly)
- Todas as transforma√ß√µes em `ColumnTransformer` (sem vazamento de dados)

### 3. Constru√ß√£o de Modelos

**Modelos Base Testados:**
- **Random Forest**: M√©todo ensemble (modelo prim√°rio) ‚úÖ
- **Logistic Regression**: Baseline r√°pido
- **Gradient Boosting**: Ensemble alternativo
- **Extra Trees**: Varia√ß√£o de Random Forest
- **LightGBM**: Gradient boosting eficiente
- **CatBoost**: Gradient boosting com categorical features
- **14 modelos no total** testados no Model Zoo

**Melhor Abordagem:**
- **Hard Voting Ensemble** com 2 Random Forests (RF_Original + RF_Poly)

### 4. Valida√ß√£o Cruzada
- 10-fold Stratified K-Fold (para modelos finais)
- 5-fold para experimentos r√°pidos
- M√©tricas: Acur√°cia, Precis√£o, Recall, F1-score
- Resultados salvos em `reports/cv_metrics.csv`

### 5. Ajuste de Hiperpar√¢metros

**M√©todos Testados:**
- RandomizedSearchCV (30 itera√ß√µes, 5-fold CV)
- GridSearchCV (216 combina√ß√µes) - **N√£o recomendado** (overfitting)
- Bayesian Optimization com Optuna (150 trials) - **N√£o recomendado** (overfitting)

**Espa√ßo de Busca:**
- n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features
- Melhores par√¢metros salvos em `reports/best_rf_params.json`

**Li√ß√£o Aprendida:** Ajuste excessivo prejudica a generaliza√ß√£o.

### 6. Treinamento Final & Predi√ß√£o
- Treinar melhor modelo em 100% dos dados de treino
- Gerar predi√ß√µes para conjunto de teste
- Criar arquivo de submiss√£o no formato requerido
- **Ensemble de vota√ß√£o majorit√°ria** para robustez

---

## ‚úÖ Garantias de Conformidade

| Requisito | Status | Detalhes |
|-----------|--------|----------|
| **Bibliotecas** | ‚úì | Apenas numpy, pandas, scikit-learn para ML |
| **Visualiza√ß√£o** | ‚úì | Apenas matplotlib (obrigat√≥rio) |
| **Fontes de Dados** | ‚úì | Apenas diret√≥rio `data/` |
| **Vazamento de Dados** | ‚úì | Todo pr√©-processamento em pipelines |
| **Reprodutibilidade** | ‚úì | `random_state=42` fixo |
| **Formato de Submiss√£o** | ‚úì | Corresponde exatamente a `sample_submission.csv` |

---

## üìà Arquivos de Sa√≠da

### Gerados pelo Pipeline

| Arquivo | Descri√ß√£o | Comando |
|---------|-----------|---------|
| `submission_majority_vote.csv` | **Melhor submiss√£o (81.88%)** | `python create_ensemble_submissions.py` |
| `submission_voting_ensemble.csv` | Soft voting ensemble (79.71%) | `python create_ensemble_submissions.py` |
| `submission_weighted_ensemble.csv` | Weighted ensemble (79.71%) | `python create_ensemble_submissions.py` |
| `reports/cv_metrics.csv` | Resultados de valida√ß√£o cruzada | `make cv` |
| `reports/best_rf_params.json` | Hiperpar√¢metros √≥timos do Random Forest | `make tune` |
| `submission.csv` | Predi√ß√µes finais (gerado por CLI) | `make submit` |

### Verifica√ß√µes de Valida√ß√£o

‚úì `submission_majority_vote.csv` tem 277 linhas (uma por amostra de teste)
‚úì `submission_majority_vote.csv` tem colunas: `id`, `labels`
‚úì `submission_majority_vote.csv` corresponde ao formato de `sample_submission.csv`
‚úì Sem valores ausentes na submiss√£o
‚úì Labels s√£o bin√°rios (0 ou 1)
‚úì Distribui√ß√£o: ~70% sucesso, ~30% falha (consistente com treino)

---

## üéØ Resultados Esperados

### Performance dos Modelos (Valida√ß√£o Cruzada)

| Modelo | Acur√°cia CV | Acur√°cia Kaggle | Gap | Status |
|--------|-------------|-----------------|-----|--------|
| **Hard Voting (RF+RF)** | **~79.5%** | **81.88%** | **+2.38pp** | ‚úÖ **MELHOR** |
| Soft Voting | ~79.5% | 79.71% | +0.21pp | Bom |
| Random Forest (Original) | 79.88% | - | - | Base |
| Random Forest (Poly) | 79.42% | - | - | Base |
| Logistic Regression | ~75-80% | - | - | Baseline |
| Gradient Boosting | ~76-82% | - | - | Alternativa |
| LightGBM (Otimizado) | 79.57% | 79.71% | +0.14pp | OK |
| GridSearchCV RF | 80.50% | 78.26% | -2.24pp | ‚ùå Overfitting |
| Stacking (5 modelos) | 79.11% | 76.09% | -3.02pp | ‚ùå Overfitting |

**Nota:** Resultados reais dependem das caracter√≠sticas dos dados e ajuste de hiperpar√¢metros.

### Conquista do Objetivo

- **Meta**: ‚â• 80% de acur√°cia no Kaggle
- **Alcan√ßado**: ‚úÖ **81.88%** com Hard Voting Ensemble
- **Supera√ß√£o**: +1.88 pontos percentuais acima da meta

---

## üîß Solu√ß√£o de Problemas

### Problemas Comuns

**Problema**: `ModuleNotFoundError: No module named 'src'`
**Solu√ß√£o**: Execute comandos a partir do diret√≥rio raiz do projeto

**Problema**: `FileNotFoundError: train.csv not found`
**Solu√ß√£o**: Certifique-se de que os arquivos de dados est√£o no diret√≥rio `data/`

**Problema**: Kernel do notebook trava durante ajuste
**Solu√ß√£o**: Reduza `n_iter` em `random_search_rf()` ou use menos folds de CV

**Problema**: Comandos do Makefile n√£o funcionam no Windows
**Solu√ß√£o**: Use Python CLI diretamente ou instale `make` para Windows

**Problema**: Submiss√£o tem formato incorreto
**Solu√ß√£o**: Verifique se o arquivo tem colunas `id` e `labels`, e 277 linhas

**Problema**: Acur√°cia muito diferente do esperado
**Solu√ß√£o**: Verifique se est√° usando `submission_majority_vote.csv` (n√£o outros arquivos)

---

## üìù Notas de Desenvolvimento

### Padr√µes de Qualidade de C√≥digo

- **Estilo**: Compat√≠vel com PEP 8
- **Docstrings**: Todas as fun√ß√µes documentadas
- **Type Hints**: Usados onde √∫til
- **Tratamento de Erros**: Falhas graciosas com mensagens claras

### Recomenda√ß√µes de Teste

```bash
# Testar carregamento de dados
python -c "from src.io_utils import load_data; load_data('data')"

# Testar pr√©-processamento
python -c "from src.features import split_columns, build_preprocessor; import pandas as pd; df = pd.DataFrame({'a': [1,2], 'b': ['x','y']}); print(split_columns(df))"

# Testar CLI
python -m src.cli --help

# Testar gera√ß√£o de ensemble
python create_ensemble_submissions.py
```

### Experimentos Realizados

**Total de Submiss√µes Testadas:** 11

1. ‚úÖ **submission_majority_vote.csv** - 81.88% (MELHOR)
2. submission_voting_ensemble.csv - 79.71%
3. submission_weighted_ensemble.csv - 79.71%
4. submission_advanced.csv - 78.99%
5. submission.csv (baseline) - 78.26%
6. submission_rf_gridsearch.csv - 78.26%
7. submission_lightgbm_optimized.csv - 79.71%
8. submission_weighted_kaggle.csv - 79.71%
9. submission_threshold_optimized.csv - 78.99%
10. submission_stacking.csv - 76.09%
11. submission_catboost_optimized.csv - Falhou (n√£o executado)

**Li√ß√£o:** Simplicidade (hard voting) venceu complexidade (stacking, otimiza√ß√£o excessiva).

---

## ü§ù Contribuindo

Este projeto segue estritamente as regras da competi√ß√£o. Melhorias sugeridas:

1. **Engenharia de Features**: Adicionar features de intera√ß√£o, raz√µes espec√≠ficas do dom√≠nio
2. **Explora√ß√£o de Modelos**: Testar redes neurais (se permitido), outros ensembles
3. **Ajuste de Hiperpar√¢metros**: Expandir espa√ßo de busca (mas cuidado com overfitting!)
4. **Valida√ß√£o**: Implementar CV aninhado para estimativas n√£o enviesadas

**Nota:** Baseado em 11 submiss√µes testadas, 81.88% parece ser o teto de performance para este dataset com as abordagens atuais.

---

## üìö Documenta√ß√£o Adicional

### An√°lises Detalhadas

- **`FINAL_RESULTS_ANALYSIS.md`** - An√°lise completa de todos os resultados
- **`JOURNEY_SUMMARY.md`** - Jornada de 78.26% ‚Üí 81.88%
- **`SUBMISSION_COMPARISON.md`** - Compara√ß√£o detalhada de todas as submiss√µes
- **`PHASE1_COMPLETE_FAILURE_ANALYSIS.md`** - An√°lise de tentativas de otimiza√ß√£o
- **`CLASSMATE_RF_GRIDSEARCH_ANALYSIS.md`** - An√°lise de abordagem alternativa

### Relat√≥rios de Progresso

- **`REALITY_CHECK_90_PERCENT_TARGET.md`** - Avalia√ß√£o realista de metas
- **`PHASE1_90_PERCENT_PUSH_PROGRESS.md`** - Progresso de tentativas de otimiza√ß√£o
- **`QUESTIONS_FOR_CLASSMATE.md`** - Perguntas para investiga√ß√£o de abordagens

---

## üìÑ Licen√ßa

Este projeto foi criado para fins educacionais como parte da competi√ß√£o [Inteli-M3] Campeonato 2025.

---

## üôè Agradecimentos

- **Organizadores da Competi√ß√£o**: [Inteli-M3] Campeonato 2025
- **Bibliotecas**: scikit-learn, pandas, numpy, matplotlib, optuna, lightgbm, catboost
- **Comunidade**: Comunidade Kaggle por inspira√ß√£o e melhores pr√°ticas

---

## üéâ Resultado Final

**üèÜ Acur√°cia Alcan√ßada: 81.88% no Kaggle**

- ‚úÖ Meta de 80% superada (+1.88pp)
- ‚úÖ 11 submiss√µes testadas
- ‚úÖ Hard Voting Ensemble com 2 Random Forests
- ‚úÖ Gap positivo de +2.38pp (excelente generaliza√ß√£o)
- ‚úÖ Abordagem simples e robusta

**Pronto para competir? Execute `python create_ensemble_submissions.py` e submeta `submission_majority_vote.csv`!** üöÄ

---

**√öltima Atualiza√ß√£o:** 2025-09-30
**Melhor Submiss√£o:** `submission_majority_vote.csv` (81.88%)
**Status:** ‚úÖ Meta alcan√ßada e superada

